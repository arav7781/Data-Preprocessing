# -*- coding: utf-8 -*-
"""WebScraping

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q2RpayBIcI13k3TyGSwH6DQvRz8SmFWj
"""

from bs4 import BeautifulSoup
import requests
#BeautifulSoup will not scrape internal web pages ont that web pages.
url = "https://www.sitpune.edu.in/"
response = requests.get(url)#connection request krne ke liye
print(response)

html_content = response.content
#content so hai sit ka html_.. variable mai store hora hai

soup = BeautifulSoup(html_content,'html.parser')
#read all the text line by line = parser.
#wikipedia se jaise copy krte h text.

soup.find('title')

soup.find('body')

soup.find('title').string
#isse HTML ke tag nhi dikhenge output mai.

h1_tags = soup.find_all('h1')

for h1 in h1_tags:
    print(h1.text)
    #for loop to print all the H1 tags from SIT.

h2_tags = soup.find_all('h2')
for h2 in h2_tags:
    print(h2.text)
    #similarly for h2 tags



h3_tags = soup.find_all('h3')
for h3 in h3_tags:
    print(h3.text)

h4_tags = soup.find_all('h4')
for h4 in h4_tags:
    print(h4.text)

h5_tags = soup.find_all('h5')
for h5 in h5_tags:
    print(h5.text)

h6_tags = soup.find_all('h6')
for h6 in h6_tags:
    print(h6.text)

#extracting the <a> tags(INT links)
a_tags = soup.find_all('a')
len(a_tags)

a_tags

list_of_links = []#to extract Hyper Link
for a in a_tags:#hyper link HREF aale
    list_of_links.append(a.get('href'))

list_of_links

import pandas as pd
df_links = pd.DataFrame(data = list_of_links,columns=['links'])
df_links

df_links.to_csv('links.csv')

all_text = soup.get_text()

all_text

li_tags = soup.find_all('li')

li_tags

for li in li_tags:
    print(li.text)

img_src = soup.find_all('img')#to find the source of the image tag in the HTML

img_src

img_links = []#common part jo hai links ka vhi uthaya hai.
link = soup.select('img[src^= "https://www.sitpune.edu.in/index/assets/images"')

for img in link:#append is to add elements in the list.
    img_links.append(img.get('src'))

directory = '/bin/scrap_images'

for index,img_link in enumerate(img_links):#enumeration is indexing along with the img links
  img_data = requests.get(img_link).content#First two lines of the code are for copying tyhe link of the image
with open(f'{directory}/'+str(index+1)+'.jpg','wb+') as file:#index + 1 use hua to give no the image pehli img 1 pe aise.
    file.write(img_data)#net two line are for pasting the links of the image.

